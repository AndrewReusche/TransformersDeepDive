{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc27d42-9457-4e1c-b469-2d65b9904caf",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ecb5f-fcf9-41e4-8a6a-49b2987ec982",
   "metadata": {},
   "source": [
    "In this section, weâ€™ll take a closer look at creating and using models. Weâ€™ll use the AutoModel class, which is handy when you want to instantiate any model from a checkpoint.\n",
    "\n",
    "## Creating a Transformer\n",
    "Letâ€™s begin by examining what happens when we instantiate an AutoModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f533da-7c48-460b-9137-1d3d7cc8b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1515f4a-a99a-46e7-87b0-37a6e08b4ce3",
   "metadata": {},
   "source": [
    "Similar to the tokenizer, the from_pretrained() method will download and cache the model data from the Hugging Face Hub. As mentioned previously, the checkpoint name corresponds to a specific model architecture and weights, in this case a BERT model with a basic architecture (12 layers, 768 hidden size, 12 attention heads) and cased inputs (meaning that the uppercase/lowercase distinction is important). There are many checkpoints available on the Hub â€” you can explore them here.\n",
    "\n",
    "The AutoModel class and its associates are actually simple wrappers designed to fetch the appropriate model architecture for a given checkpoint. Itâ€™s an â€œautoâ€ class meaning it will guess the appropriate model architecture for you and instantiate the correct model class. However, if you know the type of model you want to use, you can use the class that defines its architecture directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d145485-eb7f-4300-be1f-18cbac0082a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e179680-561b-4f5c-b153-78e164659434",
   "metadata": {},
   "source": [
    "## Loading and saving\n",
    "Saving a model is as simple as saving a tokenizer. In fact, the models actually have the same save_pretrained() method, which saves the modelâ€™s weights and architecture configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf22173c-88cc-40bf-b5e8-6581a2f97911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lesson3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b635ab-853c-4fc6-a3af-43141b5301dc",
   "metadata": {},
   "source": [
    "This will save two files to your disk:\n",
    "\n",
    "\n",
    "    ls directory_on_my_computer\n",
    "\n",
    "    config.json model.safetensors\n",
    "\n",
    "If you look inside the config.json file, youâ€™ll see all the necessary attributes needed to build the model architecture. This file also contains some metadata, such as where the checkpoint originated and what ğŸ¤— Transformers version you were using when you last saved the checkpoint.\n",
    "\n",
    "The pytorch_model.safetensors file is known as the state dictionary; it contains all your modelâ€™s weights. The two files work together: the configuration file is needed to know about the model architecture, while the model weights are the parameters of the model.\n",
    "\n",
    "To reuse a saved model, use the from_pretrained() method again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c230cab-9840-4f93-a1ee-5eb4bbdbb966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"hidden/lesson3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe1485-97bd-4a0f-bd57-82221f88a454",
   "metadata": {},
   "source": [
    "A wonderful feature of the ğŸ¤— Transformers library is the ability to easily share models and tokenizers with the community. To do this, make sure you have an account on Hugging Face. If youâ€™re using a notebook, you can easily log in with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908ba407-b1b7-4cb1-8d99-a87de01c9e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n"
     ]
    }
   ],
   "source": [
    "# only run if you don't already have\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596045ef-66ea-4bf2-8532-e04900106f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cae16220874e1b9d6941fd11c13d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This widget did not load for me so I used an alternate method\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "367ca920-e946-45fc-8aaa-502a58aadfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate method\n",
    "from huggingface_hub import login\n",
    "\n",
    "#enter your token here between () and make sure to delete after running\n",
    "#and before pushing up\n",
    "\n",
    "login(token=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b593f7-449d-4482-83d1-aa43ae98b54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '6962ca21d8c2183ea12213c9',\n",
       " 'name': 'a-reusche92',\n",
       " 'fullname': 'Andrew Reusche',\n",
       " 'email': 'andrew.j.reusche@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'billingMode': 'prepaid',\n",
       " 'periodEnd': 1769904000,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/8c92179be8b400575337a5c5476e34ed.svg',\n",
       " 'orgs': [],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'Jupyter-push',\n",
       "   'role': 'write',\n",
       "   'createdAt': '2026-01-15T00:46:55.804Z'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify your login\n",
    "\n",
    "from huggingface_hub import whoami\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89ac1a-2c52-47f2-a7e7-c3ee682da90c",
   "metadata": {},
   "source": [
    "Otherwise, at your terminal run:\n",
    "\n",
    "    huggingface-cli login\n",
    "\n",
    "Then you can push the model to the Hub with the push_to_hub() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4cbd2a-c458-42cc-993b-998a24783101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (0 / 0): |                                        |  0.00B /  0.00B            \n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  433MB /  433MB,  310MB/s  \u001b[A\n",
      "New Data Upload: |                                                 |  0.00B /  0.00B,  0.00B/s  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/a-reusche92/example_my-awesome-model/commit/b13d8c0dc0a459377d4dedc17867a23529e95283', commit_message='Upload model', commit_description='', oid='b13d8c0dc0a459377d4dedc17867a23529e95283', pr_url=None, repo_url=RepoUrl('https://huggingface.co/a-reusche92/example_my-awesome-model', endpoint='https://huggingface.co', repo_type='model', repo_id='a-reusche92/example_my-awesome-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"example_my-awesome-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "552403f3-a8b5-4a6d-aee7-94f18f061a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "#to fix future widgets\n",
    "!pip install -U ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c7e7f-e1c9-47ba-93c7-3e6fbce1ee70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
