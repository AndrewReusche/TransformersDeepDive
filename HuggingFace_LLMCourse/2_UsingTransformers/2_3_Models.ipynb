{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc27d42-9457-4e1c-b469-2d65b9904caf",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ecb5f-fcf9-41e4-8a6a-49b2987ec982",
   "metadata": {},
   "source": [
    "In this section, we‚Äôll take a closer look at creating and using models. We‚Äôll use the AutoModel class, which is handy when you want to instantiate any model from a checkpoint.\n",
    "\n",
    "## Creating a Transformer\n",
    "Let‚Äôs begin by examining what happens when we instantiate an AutoModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f533da-7c48-460b-9137-1d3d7cc8b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1515f4a-a99a-46e7-87b0-37a6e08b4ce3",
   "metadata": {},
   "source": [
    "Similar to the tokenizer, the from_pretrained() method will download and cache the model data from the Hugging Face Hub. As mentioned previously, the checkpoint name corresponds to a specific model architecture and weights, in this case a BERT model with a basic architecture (12 layers, 768 hidden size, 12 attention heads) and cased inputs (meaning that the uppercase/lowercase distinction is important). There are many checkpoints available on the Hub ‚Äî you can explore them here.\n",
    "\n",
    "The AutoModel class and its associates are actually simple wrappers designed to fetch the appropriate model architecture for a given checkpoint. It‚Äôs an ‚Äúauto‚Äù class meaning it will guess the appropriate model architecture for you and instantiate the correct model class. However, if you know the type of model you want to use, you can use the class that defines its architecture directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d145485-eb7f-4300-be1f-18cbac0082a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e179680-561b-4f5c-b153-78e164659434",
   "metadata": {},
   "source": [
    "## Loading and saving\n",
    "Saving a model is as simple as saving a tokenizer. In fact, the models actually have the same save_pretrained() method, which saves the model‚Äôs weights and architecture configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf22173c-88cc-40bf-b5e8-6581a2f97911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"lesson3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b635ab-853c-4fc6-a3af-43141b5301dc",
   "metadata": {},
   "source": [
    "This will save two files to your disk:\n",
    "\n",
    "\n",
    "    ls directory_on_my_computer\n",
    "\n",
    "    config.json model.safetensors\n",
    "\n",
    "If you look inside the config.json file, you‚Äôll see all the necessary attributes needed to build the model architecture. This file also contains some metadata, such as where the checkpoint originated and what ü§ó Transformers version you were using when you last saved the checkpoint.\n",
    "\n",
    "The pytorch_model.safetensors file is known as the state dictionary; it contains all your model‚Äôs weights. The two files work together: the configuration file is needed to know about the model architecture, while the model weights are the parameters of the model.\n",
    "\n",
    "To reuse a saved model, use the from_pretrained() method again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c230cab-9840-4f93-a1ee-5eb4bbdbb966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"hidden/lesson3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe1485-97bd-4a0f-bd57-82221f88a454",
   "metadata": {},
   "source": [
    "A wonderful feature of the ü§ó Transformers library is the ability to easily share models and tokenizers with the community. To do this, make sure you have an account on Hugging Face. If you‚Äôre using a notebook, you can easily log in with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908ba407-b1b7-4cb1-8d99-a87de01c9e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only run if you don't already have\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "596045ef-66ea-4bf2-8532-e04900106f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fc297d740f4969ac24d7b8e39e9b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This widget did not load for me so I used an alternate method\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367ca920-e946-45fc-8aaa-502a58aadfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate method\n",
    "from huggingface_hub import login\n",
    "\n",
    "#enter your token here between () and make sure to delete after running\n",
    "#and before pushing up\n",
    "\n",
    "login(token='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89ac1a-2c52-47f2-a7e7-c3ee682da90c",
   "metadata": {},
   "source": [
    "Otherwise, at your terminal run:\n",
    "\n",
    "    huggingface-cli login\n",
    "\n",
    "Then you can push the model to the Hub with the push_to_hub() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4cbd2a-c458-42cc-993b-998a24783101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (0 / 0): |                                        |  0.00B /  0.00B            \n",
      "Processing Files (1 / 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  433MB /  433MB,  310MB/s  \u001b[A\n",
      "New Data Upload: |                                                 |  0.00B /  0.00B,  0.00B/s  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/a-reusche92/example_my-awesome-model/commit/b13d8c0dc0a459377d4dedc17867a23529e95283', commit_message='Upload model', commit_description='', oid='b13d8c0dc0a459377d4dedc17867a23529e95283', pr_url=None, repo_url=RepoUrl('https://huggingface.co/a-reusche92/example_my-awesome-model', endpoint='https://huggingface.co', repo_type='model', repo_id='a-reusche92/example_my-awesome-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"example_my-awesome-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "552403f3-a8b5-4a6d-aee7-94f18f061a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/torch/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "#to fix future widgets\n",
    "!pip install -U ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c7e7f-e1c9-47ba-93c7-3e6fbce1ee70",
   "metadata": {},
   "source": [
    "This will upload the model files to the Hub, in a repository under your namespace named my-awesome-model. Then, anyone can load your model with the from_pretrained() method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78e2513-3efe-4f7f-a371-c96865e942ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc058ae635c74d08961128e9be952cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7344d71838c84d73b1a67b45407e3968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "#delete token after download\n",
    "model = AutoModel.from_pretrained(\"a-reusche92/example_my-awesome-model\", use_auth_token=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e17122-d344-4557-a420-390693c52819",
   "metadata": {},
   "source": [
    "You can do a lot more with the Hub API:\n",
    "\n",
    "    Push a model from a local repository\n",
    "    Update specific files without re-uploading everything\n",
    "Add model cards to document the model‚Äôs abilities, limitations, known biases, etc.\n",
    "See the documentation for a complete tutorial on this, or check out the advanced Chapter 4.\n",
    "\n",
    "## Encoding text\n",
    "Transformer models handle text by turning the inputs into numbers. Here we will look at exactly what happens when your text is processed by the tokenizer. We‚Äôve already seen in Chapter 1 that tokenizers split the text into tokens and then convert these tokens into numbers. We can see this conversion through a simple tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faefc756-0d8b-4615-920d-14311df7565c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4ec02d1ef041c6a8fd22dd5dd5083f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6482dd32dfab464c86dbc44d27141c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed1beb0b49440ebc6508b6e91abe67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c73e05-fad0-43cc-86f0-97da6483390a",
   "metadata": {},
   "source": [
    "We get a dictionary with the following fields:\n",
    "\n",
    "    input_ids: numerical representations of your tokens\n",
    "    token_type_ids: these tell the model which part of the input is sentence A and which is sentence B (discussed more in the next section)\n",
    "    attention_mask: this indicates which tokens should be attended to and which should not (discussed more in a bit)\n",
    "We can decode the input IDs to get back the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0f5867f-20ad-4424-9f08-808561c04284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Hello, I ' m a single sentence! [SEP]\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a94b1c-0cf4-40e7-bd39-ff646fc1af51",
   "metadata": {},
   "source": [
    "You‚Äôll notice that the tokenizer has added special tokens ‚Äî [CLS] and [SEP] ‚Äî required by the model. Not all models need special tokens; they‚Äôre utilized when a model was pretrained with them, in which case the tokenizer needs to add them as that model expects these tokens.\n",
    "\n",
    "You can encode multiple sentences at once, either by batching them together (we‚Äôll discuss this soon) or by passing a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "177b20c1-f6ec-4ba9-86c9-1139467719af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 1731, 1132, 1128, 136, 102], [101, 146, 112, 182, 2503, 117, 6243, 1128, 106, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer([\"How are you?\", \"I'm fine, thank you!\"])\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe355b-0bf2-4fd8-acde-57cfafa5e645",
   "metadata": {},
   "source": [
    "Note that when passing multiple sentences, the tokenizer returns a list for each sentence for each dictionary value. We can also ask the tokenizer to return tensors directly from PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99c63725-4ca5-4751-bab6-cf3975d62afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  136,  102,    0,    0,    0,    0],\n",
      "        [ 101,  146,  112,  182, 2503,  117, 6243, 1128,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "#code did not work, so i fixed it and now it disregards the \n",
    "# next padding comment and size comment\n",
    "\n",
    "encoded_input = tokenizer([\"How are you?\", \"I'm fine, thank you!\"],\n",
    "                          return_tensors=\"pt\",\n",
    "                          padding= True,\n",
    "                          truncation= True\n",
    "                         )\n",
    "print(encoded_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3a846-b08d-486a-8156-58d8ee1d8137",
   "metadata": {},
   "source": [
    "But there‚Äôs a problem: the two lists don‚Äôt have the same length! Arrays and tensors need to be rectangular, so we can‚Äôt simply convert these lists to a PyTorch tensor (or NumPy array). The tokenizer provides an option for that: padding.\n",
    "\n",
    "## Padding inputs\n",
    "If we ask the tokenizer to pad the inputs, it will make all sentences the same length by adding a special padding token to the sentences that are shorter than the longest one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf0e82bf-1d8f-4172-878c-6993ab336f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding alreaddy added above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad58e0-8cbe-4e6b-a982-913f92cb4a0c",
   "metadata": {},
   "source": [
    "Now we have rectangular tensors! Note that the padding tokens have been encoded into input IDs with ID 0, and they have an attention mask value of 0 as well. This is because those padding tokens shouldn‚Äôt be analyzed by the model: they‚Äôre not part of the actual sentence.\n",
    "\n",
    "## Truncating inputs\n",
    "The tensors might get too big to be processed by the model. For instance, BERT was only pretrained with sequences up to 512 tokens, so it cannot process longer sequences. If you have sequences longer than the model can handle, you‚Äôll need to truncate them with the truncation parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48cc1c8-47fc-4049-99d2-b747d742a638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1188, 1110, 170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1263, 5650, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\n",
    "    \"This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long sentence.\",\n",
    "    truncation=True,\n",
    ")\n",
    "print(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02f020-4a7d-4585-ba93-14a7ed746fa4",
   "metadata": {},
   "source": [
    "By combining the padding and truncation arguments, you can make sure your tensors have the exact size you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ad293e0-e845-4bcb-b382-61adc0d25c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  102],\n",
      "        [ 101,  146,  112,  182,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\n",
    "    [\"How are you?\", \"I'm fine, thank you!\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=5,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ed5aa-f837-40db-845b-3eaa7d0fb05a",
   "metadata": {},
   "source": [
    "## Adding special tokens\n",
    "Special tokens (or at least the concept of them) is particularly important to BERT and derived models. These tokens are added to better represent the sentence boundaries, such as the beginning of a sentence ([CLS]) or separator between sentences ([SEP]). Let‚Äôs look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0963d45-4275-410a-a333-90285652d82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1731, 1132, 1128, 136, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] How are you? [SEP]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"How are you?\")\n",
    "print(encoded_input[\"input_ids\"])\n",
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d08311-3bed-4bcb-836b-243e649cf94a",
   "metadata": {},
   "source": [
    "These special tokens are automatically added by the tokenizer. Not all models need special tokens; they are primarily used when a model was pretrained with them, in which case the tokenizer will add them since the model expects them.\n",
    "\n",
    "## Why is all of this necessary?\n",
    "Here‚Äôs a concrete example. Consider these encoded sequences:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa13ed-a174-4e19-b6ee-b056ecc42e79",
   "metadata": {},
   "source": [
    "FIXEDDDDDD BECAUSE WEBSITE CODE IS TRASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2546d6f-8ac1-4947-993a-d01ad685ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71ec3328-faba-409f-817e-9ca107b718e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(sequences,\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        return_tensors=\"pt\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec7f808e-76a3-4dfb-a4b5-7063b0321d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   146,   112,  1396,  1151,  2613,  1111,   170, 20164, 10932,\n",
      "          2271,  7954,  1736,  1139,  2006,  1297,   119,   102],\n",
      "        [  101,   146,  4819,  1142,  1177,  1277,   106,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dacb05-7d68-4a26-8e51-7a89ea8fe0e4",
   "metadata": {},
   "source": [
    "This is a list of encoded sequences: a list of lists. Tensors only accept rectangular shapes (think matrices). This ‚Äúarray‚Äù is already of rectangular shape, so converting it to a tensor is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1dc9047-668f-4d6a-82e8-a91c5917535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences= encoded_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddefcbe-d120-4f09-a271-0b0b85b521a3",
   "metadata": {},
   "source": [
    "## Using the tensors as inputs to the model\n",
    "Making use of the tensors with the model is extremely simple ‚Äî we just call the model with the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bb307e7-f7d2-4e0b-924b-83b4b7ccff9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4222,  0.4443, -0.0659,  ..., -0.1958,  0.3611,  0.1284],\n",
       "         [ 0.5728, -0.1593,  0.6014,  ..., -0.1134,  0.1791,  0.1787],\n",
       "         [ 0.4699,  0.4214,  0.1695,  ...,  0.2386,  0.9851, -0.1236],\n",
       "         ...,\n",
       "         [ 0.5847,  0.2552,  0.0266,  ...,  0.7203,  0.0650,  0.4277],\n",
       "         [ 0.5573,  0.4506,  0.0353,  ..., -0.0607,  0.4209, -0.2525],\n",
       "         [ 0.7136,  1.2932, -0.2937,  ...,  0.2917,  0.4270, -0.3874]],\n",
       "\n",
       "        [[ 0.4281,  0.5940,  0.0704,  ..., -0.2846,  0.2549,  0.0384],\n",
       "         [ 0.6010, -0.0288,  0.4811,  ..., -0.1394,  0.1924,  0.2027],\n",
       "         [ 0.2108,  0.2552, -0.4616,  ...,  0.3663, -0.0610,  0.3810],\n",
       "         ...,\n",
       "         [-0.2789, -0.3556,  0.0440,  ..., -0.4985,  0.5493,  0.3444],\n",
       "         [-0.2533, -0.3874,  0.0834,  ..., -0.5131,  0.5479,  0.2973],\n",
       "         [-0.1941, -0.4243,  0.1305,  ..., -0.5704,  0.5147,  0.2279]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6911,  0.4541,  0.9999,  ...,  1.0000, -0.8468,  0.9912],\n",
       "        [-0.5828,  0.5010,  0.9999,  ...,  1.0000, -0.6827,  0.9943]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(encoded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83b5c5-e5cf-4135-bc65-cb3a93ede14c",
   "metadata": {},
   "source": [
    "While the model accepts a lot of different arguments, only the input IDs are necessary. We‚Äôll explain what the other arguments do and when they are required later, but first we need to take a closer look at the tokenizers that build the inputs that a Transformer model can understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b0970-9274-46ff-88cc-c1552a1bf175",
   "metadata": {},
   "source": [
    "WEBSITE TRASH BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7be69c97-0807-4f70-9e37-fffea90e8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = [\n",
    "    [\n",
    "        101,\n",
    "        1045,\n",
    "        1005,\n",
    "        2310,\n",
    "        2042,\n",
    "        3403,\n",
    "        2005,\n",
    "        1037,\n",
    "        17662,\n",
    "        12172,\n",
    "        2607,\n",
    "        2026,\n",
    "        2878,\n",
    "        2166,\n",
    "        1012,\n",
    "        102,\n",
    "    ],\n",
    "    [101, 1045, 5223, 2023, 2061, 2172, 999, 102],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b28e0-ecc3-4a0d-b18f-efda7ede2ee8",
   "metadata": {},
   "source": [
    "This is a list of encoded sequences: a list of lists. Tensors only accept rectangular shapes (think matrices). This ‚Äúarray‚Äù is already of rectangular shape, so converting it to a tensor is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06f4b392-a6aa-4ff6-bdc8-df04ab1d0890",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 16 at dim 1 (got 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model_inputs = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_sequences\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: expected sequence of length 16 at dim 1 (got 8)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_inputs = torch.tensor(encoded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a9f351-9a87-4051-a0a7-14b7073138df",
   "metadata": {},
   "source": [
    "## Using the tensors as inputs to the model\n",
    "Making use of the tensors with the model is extremely simple ‚Äî we just call the model with the inputs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd891e05-e79b-41f9-bbde-7e1384779355",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f4fca-876f-4483-9640-2dacb3666886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
